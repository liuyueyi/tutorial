import{_ as t,V as o,W as _,Y as l}from"./framework-b1bd8911.js";const e={},c=l("<blockquote><p>本部分目标：</p><ul><li>回答一个被第三部分自然逼出来的问题：<strong>当知识不适合继续放进上下文时，系统还能做什么？</strong></li><li>从“工程决策”的角度理解 RAG，而不是把它当作一个流行方案</li><li>让企业知识库助手第一次真正具备<strong>事实层面的可靠性</strong></li></ul></blockquote><p>在第三部分中，我们已经明确了一个结论：</p><blockquote><p><strong>上下文与记忆解决的是“时间一致性”，而不是“知识充分性”。</strong></p></blockquote><p>这意味着：</p><ul><li>即使你完美管理了上下文（比如精准控制对话历史的长度、按优先级筛选关键信息）</li><li>即使 Prompt 约束得再严格（比如明确要求 “只基于给定信息回答”）</li></ul><p>只要问题超出了模型当前上下文中的信息范围，系统依然会被迫在“回答”和“胡说”之间做选择。而在多数未经特殊设计的系统中，模型会默认选择后者（因为 “生成内容” 是它的核心指令）。</p><p>第四部分要解决的，正是这个 “知识覆盖范围” 与 “回答可靠性” 的核心矛盾。</p>",7),s=[c];function n(r,i){return o(),_("div",null,s)}const u=t(e,[["render",n],["__file","15.第四部分 RAG与外部知识注入.html.vue"]]);export{u as default};
