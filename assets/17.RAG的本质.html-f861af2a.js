import{_ as l,V as o,W as t,$ as n,a1 as i,F as r}from"./framework-094145d2.js";const a="/tutorial/imgs/column/llm/17-1.webp",p={},d=i('<p>RAG（Retrieval-Augmented Generation）通常被介绍为：</p><blockquote><p><em>在生成前检索相关知识，作为上下文提供给模型。</em></p></blockquote><p>这个定义并没有错，但它隐藏了真正重要的工程价值。</p><hr><h3 id="_11-1-一个更准确的工程视角" tabindex="-1"><a class="header-anchor" href="#_11-1-一个更准确的工程视角" aria-hidden="true">#</a> 11.1 一个更准确的工程视角</h3><p>从系统设计角度，RAG 的核心作用可以被描述为：</p><blockquote><p><strong>在生成前，动态构造一个“最小且相关的知识上下文”。</strong></p></blockquote><p>请注意两个关键词：</p><ul><li><strong>动态</strong>：每次问题都不同，检索的知识也不同（比如用户问 A 产品时找 A 的文档，问 B 产品时找 B 的文档）</li><li><strong>最小</strong>：只注入必要信息（比如用户问 “A 产品的定价”，就只塞定价相关的片段，而非整份产品手册）</li></ul><p>这正好弥补了上下文窗口的先天不足：不再需要把所有知识塞进窗口，而是只在需要时 “临时调取” 相关部分，既避免了窗口溢出，又减少了注意力竞争。</p><p>举个实际场景：</p><ul><li>企业知识库有 1000 份文档（总大小 100 万 tokens）</li><li>用户问：“新员工入职流程中，需要提交哪些材料？”</li><li>RAG 系统会： <ul><li>从 1000 份文档中检索出 “新员工入职手册 v2.3”</li><li>从手册中提取出 “材料提交” 章节的第 3-5 段（共 500 tokens）</li><li>把这 500 tokens 作为知识上下文传给模型</li></ul></li><li>最终模型的输入是：行为约束（100 tokens）+ 相关知识（500 tokens）+ 用户问题（50 tokens），总大小 650 tokens，远低于窗口限制。</li></ul><hr><h3 id="_11-2-rag-在企业知识库助手中的位置" tabindex="-1"><a class="header-anchor" href="#_11-2-rag-在企业知识库助手中的位置" aria-hidden="true">#</a> 11.2 RAG 在企业知识库助手中的位置</h3>',14),s=i('<figure><img src="'+a+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>在这个结构中，每个模块的职责被清晰拆分：</p><ul><li>**检索器：**负责 “找知识”。输入用户问题，输出最相关的文档片段（比如通过向量相似度计算、关键词匹配等方式）。</li><li>**企业知识库：**负责 “存知识”。以结构化 / 非结构化形式存储所有文档（比如拆分成 Chunk 后，用向量数据库存储）。</li><li>**上下文构建器：**负责 “拼上下文”。把检索到的知识片段、行为约束、用户问题整合成模型能理解的输入格式。</li><li>**LLM：**负责 “生成回答”。基于构建好的上下文，输出符合约束的结果。</li></ul><p>简单来说：</p><ul><li>Prompt 负责约束</li><li>Context Engineering 负责拼装</li><li>RAG 负责<strong>把正确的知识“带回来”</strong></li></ul><hr><h3 id="_11-3-一个关键结论" tabindex="-1"><a class="header-anchor" href="#_11-3-一个关键结论" aria-hidden="true">#</a> 11.3 一个关键结论</h3><blockquote><p><strong>RAG 并不能保证“回答正确”， 但它能保证： 模型“有机会看到正确答案”。</strong></p></blockquote><p>这听起来像是退步，但实际上是系统设计的关键飞跃：</p><ul><li>从不可控 → 可控：以前模型回答错误可能是因为 “没见过正确信息”（无解），现在如果回答错误，至少可以定位到 “检索错了” 或 “模型没理解检索到的信息”（可优化）。</li><li>从玄学 → 工程问题：以前解决错误只能 “调 Prompt”“换模型”，现在可以通过优化检索策略、调整 Chunk 大小、完善知识库结构等可量化的工程手段改进。</li></ul><p>理解了 RAG “动态构造最小相关知识上下文” 的本质后，另一个现实问题随之而来：为什么有些团队明明接入了 RAG，检索效果却始终不理想？是模型不够强，还是哪里出了更基础的问题？</p><p>答案往往藏在 RAG 流程的起点 —— 文档如何被处理成可检索的单元。</p>',12);function u(h,c){const e=r("Mermaid");return o(),t("div",null,[d,n(e,{id:"mermaid-87",code:"eJyVVU1T20YYvvdX7Ewmp+DijzhxNZ3MAKY5JO1Mk/Tk6UG2VkYTRfJIcoEOB1Pqr8QQEgykMMV8TnzBpDEEYyvhv3S0K+lEf0JXqw/b1D1gXXalfZ/ned/32ddZhc3NgGfJrwD53b4N8O450l+j1pZxUb3St3Ctil42rKXPqFIy/+pd6TXU+2T2js12D1U27eKyVf1ofF4jWwqQEVlVTUIeCFIur/0gcxDwgigyt2CEj/NwTNUU+TlkboWjiQQX8bahWYHTZphobm5MkfMSBzkmEs7NDQMqUFME+AsrDoDyMRjn4wHoN5no/XT4JqCqJitsFg5C8gTUxyDb+P1M+EaQClTz4mDmPA/D6WiACPl7N0TMyMqQwgy8CzMBXiYaScTTw3ixa3hjvCxpoVkoZGc0Ji2L3DCBKL4Y7FSCj8NEgB9LJGDMp/s/vX3zdNDlEj5bNJuviHnMehNXzu3Nlr3/DvxdegvwQcE83XeX66dotUKXjx9/TwEmUoMB36aV8Qc/qVABP+ahMv8zwzB9U4VCD8BkyoVDfzTp2SeuQ6BCd1d6BRXbdr1lnSyPo9U3dvm1e/xKrzpYQ36i9H4SZuPIOimh7prRPTS6b+nrSYdxATtf9hfAVMrQF43OVnCSMk5LGlRyiqBC8EiSZ0XIZSGYZFXo6zF7a3jnd1TbuGP/uRNs8PoHvNzyVA0YkvJOUV7rso62dxZAMmVud0hWeKOM9w7Mahm3zrzURZKKpIGknMm/gGTxVBJyOaipPvczORd6BMyPX1C5hGoX5OIGdfD9OlQEo/PS6LxyiGifjM6K0yZgfVgiPaKHkm5J2k1UPFoA06l+BEmr1/W7MkWsB+c0MJkXRK7fG1e8ebxtF6p38K5OZg7eLVNxG54y3/eUbZq2/LsUERG0t9E1uituU43LPbx4YtYbuLJKSmUe1z0Qz9vXHdpuWu8PHIf+doHfrYAnEw+9L0bvHBV0elqSNZj6p7FW8z7ZhZ715Q0J8ozGiqGJfNapNuTAQyhBhdUEWSLKCByhpzrtwpZ1WXZFWntHqFhEhxv2UtO1DhmnRAcqtWlx3Xd48xNer+DC+3FSDXOvRVbuhXDScTQFNVG1eRFSmf5oYJ0nuLppznn8q8ux6gyrKOw8EwMxdyKowq+QiZDbHJTHbB2jw1P3P4BkivSu49CzRXKBiO/8KS8K0vOnlDxMRLhk9yLOMzwnIl/HvWHWj4gEEaPGNY34r+IwCF+DiQYwo0b0KOJYEDFqBI+KuBtEjBqyTtn+BYroJM4="}),s])}const m=l(p,[["render",u],["__file","17.RAG的本质.html.vue"]]);export{m as default};
