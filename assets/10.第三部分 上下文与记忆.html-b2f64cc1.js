const t=JSON.parse('{"key":"v-ad82df2a","path":"/column/ai/llmcoding/10.%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%20%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%8E%E8%AE%B0%E5%BF%86.html","title":"第三部分｜上下文与记忆：让企业知识库助手在时间维度上可靠","lang":"zh-CN","frontmatter":{"order":10,"title":"第三部分｜上下文与记忆：让企业知识库助手在时间维度上可靠","tag":["LLM"],"category":["LLM"],"date":"2025-12-30T13:55:07.000Z","keywords":"LLM应用开发","description":"本部分目标： 解释一个几乎所有真实 LLM 系统都会遇到的问题：为什么对话一变长，系统就开始失控？ 引入并系统化「Context Engineering（上下文工程）」这一核心思想 让企业知识库助手从“单轮可用”，升级为“多轮可信” 在第二部分中，我们通过 Prompt 工程为模型建立了单次生成层面的约束—— 比如明确系统角色、限定回答范围、规范输出格式等。这些方法在单轮对话中往往能取得不错的效果：用户问一个问题，系统基于设定的规则和知识库给出答案，看起来既准确又可靠。","head":[["meta",{"property":"og:url","content":"https://liuyueyi.github.io/tutorial/column/ai/llmcoding/10.%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%20%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%8E%E8%AE%B0%E5%BF%86.html"}],["meta",{"property":"og:site_name","content":"一灰灰的站点"}],["meta",{"property":"og:title","content":"第三部分｜上下文与记忆：让企业知识库助手在时间维度上可靠"}],["meta",{"property":"og:description","content":"本部分目标： 解释一个几乎所有真实 LLM 系统都会遇到的问题：为什么对话一变长，系统就开始失控？ 引入并系统化「Context Engineering（上下文工程）」这一核心思想 让企业知识库助手从“单轮可用”，升级为“多轮可信” 在第二部分中，我们通过 Prompt 工程为模型建立了单次生成层面的约束—— 比如明确系统角色、限定回答范围、规范输出格式等。这些方法在单轮对话中往往能取得不错的效果：用户问一个问题，系统基于设定的规则和知识库给出答案，看起来既准确又可靠。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-31T02:21:16.000Z"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:published_time","content":"2025-12-30T13:55:07.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-31T02:21:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第三部分｜上下文与记忆：让企业知识库助手在时间维度上可靠\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-12-30T13:55:07.000Z\\",\\"dateModified\\":\\"2025-12-31T02:21:16.000Z\\",\\"author\\":[]}"]]},"headers":[],"git":{"createdTime":1767147676000,"updatedTime":1767147676000,"contributors":[{"name":"yihui","email":"bangzewu@126.com","commits":1}]},"readingTime":{"minutes":1.37,"words":411},"filePathRelative":"column/ai/llmcoding/10.第三部分 上下文与记忆.md","localizedDate":"2025年12月30日","excerpt":"<blockquote>\\n<p>本部分目标：</p>\\n<ul>\\n<li>解释一个几乎所有真实 LLM 系统都会遇到的问题：<strong>为什么对话一变长，系统就开始失控？</strong></li>\\n<li>引入并系统化「Context Engineering（上下文工程）」这一核心思想</li>\\n<li>让企业知识库助手从“单轮可用”，升级为“多轮可信”</li>\\n</ul>\\n</blockquote>\\n<p>在第二部分中，我们通过 Prompt 工程为模型建立了单次生成层面的约束—— 比如明确系统角色、限定回答范围、规范输出格式等。这些方法在单轮对话中往往能取得不错的效果：用户问一个问题，系统基于设定的规则和知识库给出答案，<em>看起来</em>既准确又可靠。</p>","copyright":{},"autoDesc":true}');export{t as data};
