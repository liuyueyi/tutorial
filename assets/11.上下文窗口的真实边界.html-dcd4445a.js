import{_ as t,V as o,W as a,$ as e,Y as n,F as p}from"./framework-b1bd8911.js";const r="/tutorial/imgs/column/llm/11-1.webp",c={},l=n(`<p>在讨论“记忆”之前，我们必须先回答一个<strong>技术决策层面的问题</strong>：</p><blockquote><p><strong>当用户开始连续提问时，我们是否应该“尽量多地保留历史对话”？</strong></p></blockquote><p>很多团队在这个问题上的直觉答案是：</p><blockquote><p><em>当然要保留，历史越完整，模型越能理解上下文，回答自然更准确</em></p></blockquote><p>但这一章要做的事情，正是<strong>推翻这个直觉</strong> —— 因为 “全量保留历史” 不仅无法解决问题，反而会埋下系统失控的隐患。</p><hr><h3 id="_6-1-一个常被忽略的事实-上下文不是记忆" tabindex="-1"><a class="header-anchor" href="#_6-1-一个常被忽略的事实-上下文不是记忆" aria-hidden="true">#</a> 6.1 一个常被忽略的事实：上下文不是记忆</h3><p>在 LLM 的 API 交互中，我们通常通过 messages 参数传入对话历史，格式类似这样：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">[</span>
  <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span> <span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;content&quot;</span><span class="token operator">:</span> <span class="token string">&quot;...&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;content&quot;</span><span class="token operator">:</span> <span class="token string">&quot;...&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span> <span class="token string">&quot;assistant&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;content&quot;</span><span class="token operator">:</span> <span class="token string">&quot;...&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这很容易让人产生一个工程误判：</p><blockquote><p>“只要我把历史消息都塞进去，模型就能记住一切。”</p></blockquote><p>但如果回到第一部分对 LLM 本质 —— <strong><code>token</code>序列的概率预测模型</strong> —— 的分析，你会发现：</p><ul><li>模型接收的所有上下文（包括系统提示、用户提问、历史回答）会被<strong>一次性拼接成一个长 <code>token</code> 序列</strong>（比如上述示例会变成 “<code>&lt;system&gt;</code>你是企业知识库助手...<code>&lt;user&gt;</code>请问年假怎么申请？<code>&lt;assistant&gt;</code>需通过 OA 系统...”）</li><li>它并不知道哪些是“历史”，哪些是“当前”（即它只会基于整个序列的统计规律预测下一个 token）</li><li>更不知道哪些信息<strong>在工程上更重要</strong>（比如 “仅回答内部政策”），哪些是 “临时的无关信息”。</li></ul><p>因此，一个关键认知是：</p><blockquote><p><strong>上下文只是输入数据，而不是记忆机制。</strong></p></blockquote><p>人类的记忆会主动筛选、分层、关联信息，而上下文只是无序的信息堆砌。</p><hr><h3 id="_6-2-上下文窗口的三个硬限制-为什么-全塞进去-一定会失败" tabindex="-1"><a class="header-anchor" href="#_6-2-上下文窗口的三个硬限制-为什么-全塞进去-一定会失败" aria-hidden="true">#</a> 6.2 上下文窗口的三个硬限制（为什么“全塞进去”一定会失败）</h3><p>即使你愿意无条件保留所有历史，对话系统也会很快撞上三个不可绕过的限制：</p><ol><li><strong>长度上限</strong>：超过窗口，信息会被直接截断</li></ol><p>所有 LLM 都有明确的 token 长度限制（比如 GPT-3.5 为 4k token，GPT-4 基础版为 8k token，增强版为 128k token）。当历史对话累积的 token 数超过这个上限时，系统只能通过 “截断” 处理（通常是删除最早的内容），这会直接导致早期关键信息（比如系统约束）丢失。举例：如果系统提示包含</p><p><em>“禁止回答外部政策”，但随着对话变长，这条约束被挤出窗口，模型就可能开始回答无关内容。</em></p><ol start="2"><li><strong>注意力衰减</strong>：越靠前的信息，影响力越弱</li></ol><p><em>举例：用户在第 1 轮提到 “我是市场部员工”，到第 10 轮询问报销政策时，模型可能已经 “忽略” 了这个身份信息，给出了不适用的规则。</em></p><ol start="3"><li><strong>成本与延迟</strong>：token 越多，系统越慢、越贵</li></ol><p>LLM 的调用成本（按 token 计费）和响应延迟与上下文长度正相关。全量保留历史会导致每轮对话的 token 数持续增长，直接推高系统成本（可能是初始成本的 10 倍以上），同时延长用户等待时间（从几百毫秒增至几秒）。</p><p>这些限制最终会导致一个危险的后果：</p><blockquote><p><strong>最早写下的系统约束（比如 “仅用知识库内容回答”“不泄露隐私”），反而最先失效。</strong></p></blockquote><hr><h3 id="_6-3-技术决策的失败路径-对话为什么会-慢慢跑偏" tabindex="-1"><a class="header-anchor" href="#_6-3-技术决策的失败路径-对话为什么会-慢慢跑偏" aria-hidden="true">#</a> 6.3 技术决策的失败路径：对话为什么会“慢慢跑偏”？</h3><p>当我们坚持 “全量保留历史对话” 时，对话系统会沿着一条可预见的路径逐渐失控，我们可以用一个流程图来理解这个过程：</p><figure><img src="`+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',32),i=n('<p>这并不是模型突然变差，而是系统在时间维度上<strong>失去了对约束的控制权</strong>。每一轮对话都会让关键规则的影响力减弱一分，直到最后完全失效。</p><p><em>比如，一个初始设定为 “仅回答薪酬相关问题” 的助手，在多轮对话后可能会开始回应 “公司地址”“产品价格” 等无关内容 —— 不是它 “忘记” 了规则，而是规则在上下文序列中被稀释到几乎无法影响预测结果。</em></p><hr><h3 id="_6-4-本章小结-一个必须接受的结论" tabindex="-1"><a class="header-anchor" href="#_6-4-本章小结-一个必须接受的结论" aria-hidden="true">#</a> 6.4 本章小结：一个必须接受的结论</h3><p>通过本章的分析，我们可以得出一个明确的结论：</p><ul><li>“尽量保留所有上下文”是一个<strong>工程反模式(Anti-pattern)</strong>，它会导致约束失效、成本飙升、体验下降。</li><li>上下文窗口无法承担“长期记忆”的职责，其本质上是 “一次性输入缓冲区”</li></ul><p>既然全量保留不可行，那自然会引出下一个问题：</p><blockquote><p><strong>如果不能无脑堆上下文，那我们到底该保留什么？</strong></p></blockquote><p>这正是下一章要解决的核心问题 —— 从 “被动堆积上下文” 转向 “主动管理上下文”。</p>',9);function u(d,k){const s=p("Mermaid");return o(),a("div",null,[l,e(s,{id:"mermaid-124",code:"eJydk11P01AYx+/9FCcx3jHZS1DSGBNl+JIYL1CvFi+69VQaa7u0RfBuU9k62AsiAyYiTmAbGkBehG1M+C5k55z2Cj+Cp6esMOINtkmTnvb8fs95zv+80Pj4MHg0dAXQ69o1gL/uo1YBbXxqNzInrU84m7GX83ZpjdQmUbNiJ6atowV7PGdlttmMmMzrehiKQFIk47EqQCBKssxdhQGxT4Q9uqGpLyF31R/s7xcCp6++UUkwhrlgfKxHU0cUAQpcwB8f6+aN8pri8AKnQFEUQ9DvAcW+mzF/5/VSwKAHhP5o0ANC8cZ/AkMeMBbrP6sQ3ugLXA6oSfrLcy2kBUbhWQuFUFAMit280AVej6gqhm8USi+GDS6qykK3QFENeF7AO7cniArO3REIvD7Maxr/hguBkCfppzWfJaWOjt7hX0kaDScpc19xvkp2N0l1ExynpoGdmMLrqzi5h7KzbIDM1LC5T+YWyNsGg9yJoI0sLu62jxZJsYTyKVTYRpsNa3PxVlTrvX1vRJbBA0k3VO0NGIIGVAxJVZ5zHOeFzee7De5G2vWJdn0Sz6ZxNkkO1q1UzXqXYIgB2g84ZoCHiijzzmw2etIyn9I1KgDvmVZizl4uoVz6pJVx0F7uWIV3mWEggsZ37JkN0qzgxSXr2w9SS9jpiV5sfsez6x0RbRwvKYYOwpI84rh6n2ojSqxL6/bMqr5HZgmtbOGieUEbZNoBpg1HcK2MvkySmSVsTpG1pj23izNraKXKcPehAjVGB0/ifAyCwbE4r+jnbNSA8gfWYYMUs27tF2whZgsz22AELXwh6zPOttWnULJAKgduoQw3BPU4XSMEYfha6lqTdfgRpZvWbs1OF+g22KXcPy2DzHIv4qYAFXJ2xTxOfLaSE2Qx4T7Rz612PUcTgCa2283UccLNwTMdamBAfRWXWX8ddOeoeGG0yqtofBzv1KzqMg0jTRiez3e6vYxSO3i2gcsm+905BpE/S9Nl0G7N03C6n+gsN3v4w7xVSaL8JGmtgV5wfuvJ7w27vEcHnbAXTTex1lEaH6w4VXXOlxtu4LtOF+yMgSt/Ad+Bcgk="}),i])}const m=t(c,[["render",u],["__file","11.上下文窗口的真实边界.html.vue"]]);export{m as default};
