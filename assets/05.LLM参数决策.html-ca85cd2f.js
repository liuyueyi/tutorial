const e=JSON.parse('{"key":"v-7fec70b4","path":"/column/ai/llmcoding/05.LLM%E5%8F%82%E6%95%B0%E5%86%B3%E7%AD%96.html","title":"第 2 章：模型不是重点，参数才是你真正的控制面板","lang":"zh-CN","frontmatter":{"order":5,"title":"第 2 章：模型不是重点，参数才是你真正的控制面板","tag":["LLM"],"category":["LLM"],"date":"2025-12-30T11:15:07.000Z","keywords":"LLM应用开发","description":"在了解 LLM 的基本工作方式之后，我们来看一个实际体验中很常见的问题： 为什么同一个模型、同样的 Prompt， 有时表现很好，有时却很糟糕？ 2.1 一个常见困惑：为什么效果忽好忽坏？ 在实际使用中，我们可能都遇到过，选择了更牛的模型、也按照要求反复调整了提示词，在demo中表现挺好，可是只要一上线，各种问题就来了，如 输出不稳定 有时啰嗦，有时过于简短 出现不符合现状或者自相矛盾的结果","head":[["meta",{"property":"og:url","content":"https://liuyueyi.github.io/tutorial/column/ai/llmcoding/05.LLM%E5%8F%82%E6%95%B0%E5%86%B3%E7%AD%96.html"}],["meta",{"property":"og:site_name","content":"一灰灰的站点"}],["meta",{"property":"og:title","content":"第 2 章：模型不是重点，参数才是你真正的控制面板"}],["meta",{"property":"og:description","content":"在了解 LLM 的基本工作方式之后，我们来看一个实际体验中很常见的问题： 为什么同一个模型、同样的 Prompt， 有时表现很好，有时却很糟糕？ 2.1 一个常见困惑：为什么效果忽好忽坏？ 在实际使用中，我们可能都遇到过，选择了更牛的模型、也按照要求反复调整了提示词，在demo中表现挺好，可是只要一上线，各种问题就来了，如 输出不稳定 有时啰嗦，有时过于简短 出现不符合现状或者自相矛盾的结果"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-31T02:21:16.000Z"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:published_time","content":"2025-12-30T11:15:07.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-31T02:21:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第 2 章：模型不是重点，参数才是你真正的控制面板\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-12-30T11:15:07.000Z\\",\\"dateModified\\":\\"2025-12-31T02:21:16.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":3,"title":"2.1 一个常见困惑：为什么效果忽好忽坏？","slug":"_2-1-一个常见困惑-为什么效果忽好忽坏","link":"#_2-1-一个常见困惑-为什么效果忽好忽坏","children":[]},{"level":3,"title":"2.2 temperature / top_p 不是“调味料”","slug":"_2-2-temperature-top-p-不是-调味料","link":"#_2-2-temperature-top-p-不是-调味料","children":[]},{"level":3,"title":"2.3 model：不是“越强越好”，而是“是否匹配任务”","slug":"_2-3-model-不是-越强越好-而是-是否匹配任务","link":"#_2-3-model-不是-越强越好-而是-是否匹配任务","children":[]},{"level":3,"title":"2.4 max_tokens：你允许系统“说到什么程度”","slug":"_2-4-max-tokens-你允许系统-说到什么程度","link":"#_2-4-max-tokens-你允许系统-说到什么程度","children":[]},{"level":3,"title":"2.5 stream：不是体验优化，而是系统架构选择","slug":"_2-5-stream-不是体验优化-而是系统架构选择","link":"#_2-5-stream-不是体验优化-而是系统架构选择","children":[]},{"level":3,"title":"2.6 用「任务类型」来决定参数，而不是凭感觉","slug":"_2-6-用「任务类型」来决定参数-而不是凭感觉","link":"#_2-6-用「任务类型」来决定参数-而不是凭感觉","children":[]},{"level":3,"title":"2.7 把参数当成策略的一部分（伪代码示例）","slug":"_2-7-把参数当成策略的一部分-伪代码示例","link":"#_2-7-把参数当成策略的一部分-伪代码示例","children":[]},{"level":3,"title":"2.8 本章小结","slug":"_2-8-本章小结","link":"#_2-8-本章小结","children":[]}],"git":{"createdTime":1767147676000,"updatedTime":1767147676000,"contributors":[{"name":"yihui","email":"bangzewu@126.com","commits":1}]},"readingTime":{"minutes":8.51,"words":2552},"filePathRelative":"column/ai/llmcoding/05.LLM参数决策.md","localizedDate":"2025年12月30日","excerpt":"<p>在了解 LLM 的基本工作方式之后，我们来看一个<strong>实际体验中很常见的问题</strong>：</p>\\n<blockquote>\\n<p><strong>为什么同一个模型、同样的 Prompt， 有时表现很好，有时却很糟糕？</strong></p>\\n</blockquote>\\n<hr>\\n<h3> 2.1 一个常见困惑：为什么效果忽好忽坏？</h3>\\n<p>在实际使用中，我们可能都遇到过，选择了更牛的模型、也按照要求反复调整了提示词，在demo中表现挺好，可是只要一上线，各种问题就来了，如</p>\\n<ul>\\n<li>输出不稳定</li>\\n<li>有时啰嗦，有时过于简短</li>\\n<li>出现不符合现状或者自相矛盾的结果</li>\\n</ul>","copyright":{},"autoDesc":true}');export{e as data};
