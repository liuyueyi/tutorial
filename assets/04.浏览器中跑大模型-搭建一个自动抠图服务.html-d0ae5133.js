import{_ as s,V as e,W as l,X as t,Y as o,Z as n,a0 as i,F as a}from"./framework-23f3cf9b.js";const g="/tutorial/imgs/column/ai/5-1.jpg",p="/tutorial/imgs/column/ai/5-2.jpg",_="/tutorial/imgs/column/ai/5-3.gif",c={},h=i('<p>抠图的场景大家应该很熟悉了，使用大模型来抠图也属于很常见的功能了，但是在操作一些相对隐私的图片总会有一点点担心。那么在自己的电脑上跑一个大模型？ 电脑的性能够呛！ 难道就没有什么离线的大模型可以用嘛？</p><p>相信很多小伙伴都听过<code>Transformers.js</code>，一个JavaScript库，它允许开发者在浏览器或Node.js环境中使用Hugging Face的预训练机器学习模型，无需服务器支持</p><p>最近花了一点时间（主要是借助豆包）来写了一个网页，支持在浏览器本地直接跑RMBG V1.4模型，实现离线的智能抠图功能。 下来看看整体的表现情况</p><figure><img src="'+g+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>支持本地上传图片、粘贴上传图片、拖拽上传图片三种方式；首次访问网页时，会自动下载大模型(约40M)，下载成功之后会在提示区域显示“模型已加载完成”，之后所有的操作将基于用户的浏览器进行操作，无后端交互，隐私无忧</p><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="实际体验" tabindex="-1"><a class="header-anchor" href="#实际体验" aria-hidden="true">#</a> 实际体验</h3>',7),d={href:"https://ai.hhui.top/app/rmBg.html",target:"_blank",rel:"noopener noreferrer"},u=i('<p>它的核心玩法很简单粗暴：</p><ol><li>打开网页。</li><li>选择本地图片（或拖拽或粘贴一个图片）。</li><li>点击开始处理图片</li><li>几秒后（看图片大小和机器性能），抠好的图直接显示/下载。</li></ol><figure><img src="'+_+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>这体验就丝滑了：</strong></p><ul><li><strong>速度起飞：</strong> 省了上传下载的大头时间，处理速度就看用户本机CPU/GPU了。</li><li><strong>隐私拉满：</strong> 用户数据本地处理，安全感爆棚，合规风险骤降。</li><li><strong>零成本调用：</strong> 对开发者/服务提供方来说，没有图片传输的带宽成本，没有按次调用的API费用，服务器压力？不存在的！</li><li><strong>开箱即用：</strong> 用户不用装软件，不用注册，打开就用，用完就走。</li></ul><h3 id="关键技术说明" tabindex="-1"><a class="header-anchor" href="#关键技术说明" aria-hidden="true">#</a> 关键技术说明</h3><p>怎么做到的？关键点在这儿（技术老铁们看过来）：</p><ol><li><strong>模型本地化：</strong> 这个网页背后，在首次加载时（或按需），把训练好的抠图模型（onnx）<strong>直接下载到了用户的浏览器缓存里</strong>。模型大小约40M，百兆网速的小伙伴也就是几秒的加载时间。</li><li><strong>浏览器内推理引擎：</strong> 依靠的是强大的 <strong><code>transformers.js</code></strong> 。它们提供了在浏览器JavaScript环境中直接加载和运行AI模型的能力。</li></ol><p>对咱们开发者有啥启发？</p><ol><li><strong>边缘计算的魅力：</strong> 这就是“边缘计算”在Web端的生动体现啊！把计算负载从中心服务器下放到终端设备（浏览器），解决延迟、隐私、成本问题。想想看，除了抠图，像简单的图像分类、风格迁移、文本摘要、甚至轻量级的语音识别，是不是都有可能搬到浏览器里？</li><li><strong>Web ML 生态成熟：</strong> <code>transformers.js</code>、ONNX Runtime Web、TensorFlow.js 这些工具链越来越成熟，让在Web端部署和运行（尤其是优化后的）模型不再是天方夜谭。前端工程师的武器库又丰富了！</li><li><strong>用户体验新思路：</strong> 对于需要处理用户本地数据的应用（图片、文档、音视频片段），<strong>“本地优先”</strong> 的处理策略能极大提升用户体验和信任度。这个抠图工具就是个很好的样板。</li><li><strong>模型优化是王道：</strong> 浏览器环境资源有限（内存、算力），模型必须<strong>轻量化、高效化</strong>。这倒逼我们在模型设计、剪枝、量化、格式转换上做更多优化工作。</li></ol><p><strong>值得一试吗？</strong></p><p>当然！无论你是：</p><ul><li><strong>好奇宝宝：</strong> 想看看浏览器里跑模型到底啥感觉？</li><li><strong>前端攻城狮：</strong> 想探索Web ML的可能性边界？</li><li><strong>后端/全栈：</strong> 在琢磨如何降低服务端负载、优化成本结构？</li><li><strong>产品经理：</strong> 在寻找提升用户体验、增强隐私卖点的方案？</li></ul>',13),m={href:"https://ai.hhui.top/app/rmBg.html",target:"_blank",rel:"noopener noreferrer"},f=i("<p><strong>实际体验感受：</strong></p><ul><li>首次加载可能需要下载模型（40MB级别），有点耐心。</li><li>抠图速度取决于你电脑性能，实测普通照片几秒到十几秒搞定，效果在浏览器里跑成这样相当不错了（当然不能和顶级桌面软件比）。</li><li>最大的爽点：图片真的没上传！打开浏览器开发者工具 - 网络（Network）标签页，你会看到除了加载网页本身和模型文件，<strong>处理过程中没有任何图片上传的请求！</strong> 这感觉，踏实。</li></ul><p><strong>最后叨叨：</strong></p><p>这个网页虽然是个工具，但它展示的思路非常有价值。随着Web ML技术的进步和终端设备算力的提升，<strong>把更多AI能力“沉”到浏览器端</strong>，会是优化用户体验、降低成本、保护隐私的一个重要方向。对于隐私优先的小伙伴，不妨收藏一波😊</p>",4),b=t("strong",null,"链接再放一次，动手试试吧：",-1),x={href:"https://ai.hhui.top/app/rmBg.html",target:"_blank",rel:"noopener noreferrer"};function B(k,N){const r=a("ExternalLinkIcon");return e(),l("div",null,[h,t("p",null,[o("有兴趣的小伙伴可以实际体验，访问地址："),t("a",d,[o("https://ai.hhui.top/app/rmBg.html"),n(r)])]),u,t("p",null,[o("这个网页都值得你点开玩一玩："),t("strong",null,[t("a",m,[o("https://ai.hhui.top/app/rmBg.html"),n(r)])])]),f,t("p",null,[b,t("a",x,[o("https://ai.hhui.top/app/rmBg.html"),n(r)])])])}const M=s(c,[["render",B],["__file","04.浏览器中跑大模型-搭建一个自动抠图服务.html.vue"]]);export{M as default};
