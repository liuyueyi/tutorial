import{_ as a,V as e,W as r,a1 as h}from"./framework-094145d2.js";const i={},d=h('<h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言" aria-hidden="true">#</a> 前言</h2><h3 id="为什么你-会用-llm-但做不出复杂应用" tabindex="-1"><a class="header-anchor" href="#为什么你-会用-llm-但做不出复杂应用" aria-hidden="true">#</a> 为什么你“会用 LLM”，但做不出复杂应用？</h3><ul><li>为什么调得好 Prompt ≠ 系统就稳定？</li><li>为什么多数 Demo 无法上线？</li><li>本书解决什么问题、不解决什么问题</li></ul><h3 id="本书的学习路径说明" tabindex="-1"><a class="header-anchor" href="#本书的学习路径说明" aria-hidden="true">#</a> 本书的学习路径说明</h3><ul><li>你需要什么基础？</li><li>每一模块学完你“能做什么”</li><li>推荐的学习与实践方式</li></ul><hr><h1 id="第一部分-重新认识-llm-不是模型问题-而是系统问题" tabindex="-1"><a class="header-anchor" href="#第一部分-重新认识-llm-不是模型问题-而是系统问题" aria-hidden="true">#</a> 第一部分｜重新认识 LLM：不是模型问题，而是系统问题</h1><blockquote><p><strong>目标：建立“工程师视角”的 LLM 认知模型</strong></p></blockquote><hr><h2 id="第-1-章-llm-到底在做什么-程序员版认知重建" tabindex="-1"><a class="header-anchor" href="#第-1-章-llm-到底在做什么-程序员版认知重建" aria-hidden="true">#</a> 第 1 章：LLM 到底在做什么？（程序员版认知重建）</h2><h3 id="_1-1-一个反直觉的问题-llm-真的-理解-语言吗" tabindex="-1"><a class="header-anchor" href="#_1-1-一个反直觉的问题-llm-真的-理解-语言吗" aria-hidden="true">#</a> 1.1 一个反直觉的问题：LLM 真的“理解”语言吗？</h3><ul><li>如果它不理解，为什么还能推理？</li><li>“下一个 token 预测”到底意味着什么？</li></ul><h3 id="_1-2-从函数视角理解-llm" tabindex="-1"><a class="header-anchor" href="#_1-2-从函数视角理解-llm" aria-hidden="true">#</a> 1.2 从函数视角理解 LLM</h3><ul><li>LLM ≈ <code>f(context) → token</code></li><li>为什么上下文就是一切？</li><li>为什么 prompt 是“代码”？</li></ul><p>📊 <strong>图：Token 预测与采样机制示意图（mermaid）</strong></p><hr><h3 id="_1-3-你必须接受的事实-llm-天生不可靠" tabindex="-1"><a class="header-anchor" href="#_1-3-你必须接受的事实-llm-天生不可靠" aria-hidden="true">#</a> 1.3 你必须接受的事实：LLM 天生不可靠</h3><ul><li>什么是幻觉？为什么无法彻底消除？</li><li>“不知道”为什么是最难的答案？</li></ul><p>📊 <strong>图：无约束生成 vs 受约束生成对比图</strong></p><hr><h3 id="_1-4-第一性原理总结" tabindex="-1"><a class="header-anchor" href="#_1-4-第一性原理总结" aria-hidden="true">#</a> 1.4 第一性原理总结</h3><ul><li>LLM 擅长什么？</li><li>LLM 永远不该做什么？</li><li>哪些问题必须交给系统解决？</li></ul><hr><h2 id="第-2-章-模型不是重点-参数才是你真正的控制面板" tabindex="-1"><a class="header-anchor" href="#第-2-章-模型不是重点-参数才是你真正的控制面板" aria-hidden="true">#</a> 第 2 章：模型不是重点，参数才是你真正的控制面板</h2><h3 id="_2-1-一个问题-为什么同一个-prompt-效果忽好忽坏" tabindex="-1"><a class="header-anchor" href="#_2-1-一个问题-为什么同一个-prompt-效果忽好忽坏" aria-hidden="true">#</a> 2.1 一个问题：为什么同一个 Prompt 效果忽好忽坏？</h3><ul><li>随机性从哪来？</li><li>temperature / top_p 在“干什么”？</li></ul><h3 id="_2-2-参数-配置-而是策略" tabindex="-1"><a class="header-anchor" href="#_2-2-参数-配置-而是策略" aria-hidden="true">#</a> 2.2 参数 ≠ 配置，而是策略</h3><ul><li>不同任务的参数决策逻辑</li><li>为什么大多数人“乱调参”？</li></ul><p>📊 <strong>图：任务类型 → 参数决策树</strong></p><hr><h3 id="_2-3-api-调用的本质结构" tabindex="-1"><a class="header-anchor" href="#_2-3-api-调用的本质结构" aria-hidden="true">#</a> 2.3 API 调用的本质结构</h3><ul><li>messages 是“状态机”</li><li>system role 真正的权力边界</li></ul><p>🧪 示例：最小多轮对话实现（伪代码）</p><hr><h1 id="第二部分-prompt-工程-让模型-稳定干活-的第一道防线" tabindex="-1"><a class="header-anchor" href="#第二部分-prompt-工程-让模型-稳定干活-的第一道防线" aria-hidden="true">#</a> 第二部分｜Prompt 工程：让模型“稳定干活”的第一道防线</h1><blockquote><p><strong>目标：从“写提示词”升级为“设计 Prompt 结构”</strong></p></blockquote><hr><h2 id="第-3-章-prompt-为什么会失败" tabindex="-1"><a class="header-anchor" href="#第-3-章-prompt-为什么会失败" aria-hidden="true">#</a> 第 3 章：Prompt 为什么会失败？</h2><h3 id="_3-1-一个常见误区-prompt-写得越长越好" tabindex="-1"><a class="header-anchor" href="#_3-1-一个常见误区-prompt-写得越长越好" aria-hidden="true">#</a> 3.1 一个常见误区：Prompt 写得越长越好？</h3><ul><li>模糊 ≠ 自由</li><li>细节 ≠ 噪声</li></ul><h3 id="_3-2-prompt-的三条工程原则" tabindex="-1"><a class="header-anchor" href="#_3-2-prompt-的三条工程原则" aria-hidden="true">#</a> 3.2 Prompt 的三条工程原则</h3><ul><li>清晰性</li><li>约束性</li><li>可复用性</li></ul><p>📊 <strong>图：坏 Prompt vs 好 Prompt 结构对比</strong></p><hr><h2 id="第-4-章-从-zero-shot-到-few-shot-的设计思维" tabindex="-1"><a class="header-anchor" href="#第-4-章-从-zero-shot-到-few-shot-的设计思维" aria-hidden="true">#</a> 第 4 章：从 Zero-shot 到 Few-shot 的设计思维</h2><h3 id="_4-1-什么时候你真的需要-few-shot" tabindex="-1"><a class="header-anchor" href="#_4-1-什么时候你真的需要-few-shot" aria-hidden="true">#</a> 4.1 什么时候你真的需要 Few-shot？</h3><ul><li>模型不会“猜你的规则”</li></ul><h3 id="_4-2-示例驱动-prompt-的本质" tabindex="-1"><a class="header-anchor" href="#_4-2-示例驱动-prompt-的本质" aria-hidden="true">#</a> 4.2 示例驱动 Prompt 的本质</h3><ul><li>示例是在教模型“判题规则”</li></ul><p>🧪 示例：文本分类 / 数据抽取 Prompt 演进过程</p><hr><h2 id="第-5-章-prompt-模板化与工程落地" tabindex="-1"><a class="header-anchor" href="#第-5-章-prompt-模板化与工程落地" aria-hidden="true">#</a> 第 5 章：Prompt 模板化与工程落地</h2><h3 id="_5-1-为什么-prompt-必须版本化" tabindex="-1"><a class="header-anchor" href="#_5-1-为什么-prompt-必须版本化" aria-hidden="true">#</a> 5.1 为什么 Prompt 必须版本化？</h3><ul><li>Prompt 就是代码</li></ul><h3 id="_5-2-通用-prompt-模板结构" tabindex="-1"><a class="header-anchor" href="#_5-2-通用-prompt-模板结构" aria-hidden="true">#</a> 5.2 通用 Prompt 模板结构</h3><ul><li>Role</li><li>Task</li><li>Constraints</li><li>Output Schema</li></ul><p>📊 <strong>图：Prompt 模板结构图</strong></p><hr><h1 id="第三部分-上下文与记忆-对话为什么会-失忆" tabindex="-1"><a class="header-anchor" href="#第三部分-上下文与记忆-对话为什么会-失忆" aria-hidden="true">#</a> 第三部分｜上下文与记忆：对话为什么会“失忆”？</h1><blockquote><p><strong>目标：掌握对话系统设计，而不是堆 messages</strong></p></blockquote><hr><h2 id="第-6-章-上下文窗口的真实边界" tabindex="-1"><a class="header-anchor" href="#第-6-章-上下文窗口的真实边界" aria-hidden="true">#</a> 第 6 章：上下文窗口的真实边界</h2><h3 id="_6-1-上下文不是-无限内存" tabindex="-1"><a class="header-anchor" href="#_6-1-上下文不是-无限内存" aria-hidden="true">#</a> 6.1 上下文不是“无限内存”</h3><ul><li>Token 成本、性能与遗忘</li></ul><h3 id="_6-2-为什么长对话一定会崩" tabindex="-1"><a class="header-anchor" href="#_6-2-为什么长对话一定会崩" aria-hidden="true">#</a> 6.2 为什么长对话一定会崩？</h3><p>📊 <strong>图：上下文窗口滚动与信息丢失示意图</strong></p><hr><h2 id="第-7-章-三种记忆策略的工程取舍" tabindex="-1"><a class="header-anchor" href="#第-7-章-三种记忆策略的工程取舍" aria-hidden="true">#</a> 第 7 章：三种记忆策略的工程取舍</h2><h3 id="_7-1-短期记忆-直接塞上下文" tabindex="-1"><a class="header-anchor" href="#_7-1-短期记忆-直接塞上下文" aria-hidden="true">#</a> 7.1 短期记忆：直接塞上下文</h3><h3 id="_7-2-摘要记忆-用-llm-管-llm" tabindex="-1"><a class="header-anchor" href="#_7-2-摘要记忆-用-llm-管-llm" aria-hidden="true">#</a> 7.2 摘要记忆：用 LLM 管 LLM</h3><h3 id="_7-3-长期记忆-向量化存储历史" tabindex="-1"><a class="header-anchor" href="#_7-3-长期记忆-向量化存储历史" aria-hidden="true">#</a> 7.3 长期记忆：向量化存储历史</h3><p>📊 <strong>图：短 / 中 / 长期记忆系统架构对比</strong></p><p>🧪 示例：对话摘要生成伪代码</p><hr><h2 id="第-8-章-上下文工程-context-engineering" tabindex="-1"><a class="header-anchor" href="#第-8-章-上下文工程-context-engineering" aria-hidden="true">#</a> 第 8 章：上下文工程（Context Engineering）</h2><h3 id="_8-1-什么信息值得留下" tabindex="-1"><a class="header-anchor" href="#_8-1-什么信息值得留下" aria-hidden="true">#</a> 8.1 什么信息值得留下？</h3><h3 id="_8-2-信息如何-压缩但不失真" tabindex="-1"><a class="header-anchor" href="#_8-2-信息如何-压缩但不失真" aria-hidden="true">#</a> 8.2 信息如何“压缩但不失真”？</h3><h3 id="_8-3-结构化上下文设计模式" tabindex="-1"><a class="header-anchor" href="#_8-3-结构化上下文设计模式" aria-hidden="true">#</a> 8.3 结构化上下文设计模式</h3><p>📊 <strong>图：结构化上下文拼装流程图</strong></p><hr><h1 id="第四部分-能力扩展-让-llm-走出-纯聊天" tabindex="-1"><a class="header-anchor" href="#第四部分-能力扩展-让-llm-走出-纯聊天" aria-hidden="true">#</a> 第四部分｜能力扩展：让 LLM 走出“纯聊天”</h1><blockquote><p><strong>目标：让 LLM 接入真实世界，而不是只会说话</strong></p></blockquote><hr><h2 id="第-9-章-为什么单靠-llm-永远不够" tabindex="-1"><a class="header-anchor" href="#第-9-章-为什么单靠-llm-永远不够" aria-hidden="true">#</a> 第 9 章：为什么单靠 LLM 永远不够？</h2><h3 id="_9-1-知识截止的问题" tabindex="-1"><a class="header-anchor" href="#_9-1-知识截止的问题" aria-hidden="true">#</a> 9.1 知识截止的问题</h3><h3 id="_9-2-无状态的问题" tabindex="-1"><a class="header-anchor" href="#_9-2-无状态的问题" aria-hidden="true">#</a> 9.2 无状态的问题</h3><h3 id="_9-3-无执行能力的问题" tabindex="-1"><a class="header-anchor" href="#_9-3-无执行能力的问题" aria-hidden="true">#</a> 9.3 无执行能力的问题</h3><p>📊 <strong>图：LLM 核心缺陷总览</strong></p><hr><h2 id="第-10-章-function-calling-——-llm-的-决策大脑" tabindex="-1"><a class="header-anchor" href="#第-10-章-function-calling-——-llm-的-决策大脑" aria-hidden="true">#</a> 第 10 章：Function Calling —— LLM 的“决策大脑”</h2><h3 id="_10-1-模型是如何-选择工具-的" tabindex="-1"><a class="header-anchor" href="#_10-1-模型是如何-选择工具-的" aria-hidden="true">#</a> 10.1 模型是如何“选择工具”的？</h3><h3 id="_10-2-schema-设计的关键原则" tabindex="-1"><a class="header-anchor" href="#_10-2-schema-设计的关键原则" aria-hidden="true">#</a> 10.2 Schema 设计的关键原则</h3><ul><li>函数不是越多越好</li></ul><p>📊 <strong>图：Function Calling 全流程闭环</strong></p><p>🧪 示例：天气 / 数据库查询工具调用</p><hr><h2 id="第-11-章-rag-——-企业级-llm-的地基" tabindex="-1"><a class="header-anchor" href="#第-11-章-rag-——-企业级-llm-的地基" aria-hidden="true">#</a> 第 11 章：RAG —— 企业级 LLM 的地基</h2><h3 id="_11-1-为什么-rag-不是-外挂知识库" tabindex="-1"><a class="header-anchor" href="#_11-1-为什么-rag-不是-外挂知识库" aria-hidden="true">#</a> 11.1 为什么 RAG 不是“外挂知识库”？</h3><h3 id="_11-2-rag-解决的是哪一类问题" tabindex="-1"><a class="header-anchor" href="#_11-2-rag-解决的是哪一类问题" aria-hidden="true">#</a> 11.2 RAG 解决的是哪一类问题？</h3><p>📊 <strong>图：RAG 离线 + 在线全流程图</strong></p><hr><h3 id="_11-3-文档-→-chunk-→-embedding-的关键设计点" tabindex="-1"><a class="header-anchor" href="#_11-3-文档-→-chunk-→-embedding-的关键设计点" aria-hidden="true">#</a> 11.3 文档 → Chunk → Embedding 的关键设计点</h3><ul><li>切多大才合理？</li><li>为什么分割决定效果上限？</li></ul><h3 id="_11-4-检索失败的真实原因" tabindex="-1"><a class="header-anchor" href="#_11-4-检索失败的真实原因" aria-hidden="true">#</a> 11.4 检索失败的真实原因</h3><ul><li>不是模型问题，而是数据问题</li></ul><p>🧪 示例：最小 RAG 原型（伪代码）</p><hr><h1 id="第五部分-agent-思维-从调用模型到构建系统" tabindex="-1"><a class="header-anchor" href="#第五部分-agent-思维-从调用模型到构建系统" aria-hidden="true">#</a> 第五部分｜Agent 思维：从调用模型到构建系统</h1><blockquote><p><strong>目标：理解“智能体”不是框架，而是架构模式</strong></p></blockquote><hr><h2 id="第-12-章-什么是-agent-它和-prompt-的本质区别" tabindex="-1"><a class="header-anchor" href="#第-12-章-什么是-agent-它和-prompt-的本质区别" aria-hidden="true">#</a> 第 12 章：什么是 Agent？它和 Prompt 的本质区别</h2><h3 id="_12-1-为什么-cot-agent" tabindex="-1"><a class="header-anchor" href="#_12-1-为什么-cot-agent" aria-hidden="true">#</a> 12.1 为什么 CoT ≠ Agent？</h3><h3 id="_12-2-react-plan-execute-的本质抽象" tabindex="-1"><a class="header-anchor" href="#_12-2-react-plan-execute-的本质抽象" aria-hidden="true">#</a> 12.2 ReAct / Plan-Execute 的本质抽象</h3><p>📊 <strong>图：Agent 推理循环结构图</strong></p><hr><h2 id="第-13-章-一个-agent-的最小系统结构" tabindex="-1"><a class="header-anchor" href="#第-13-章-一个-agent-的最小系统结构" aria-hidden="true">#</a> 第 13 章：一个 Agent 的最小系统结构</h2><ul><li>输入解析</li><li>状态管理</li><li>工具调度</li><li>结果评估</li></ul><p>📊 <strong>图：Agent 系统架构全景图</strong></p><hr><h2 id="第-14-章-失败的-agent-都失败在哪" tabindex="-1"><a class="header-anchor" href="#第-14-章-失败的-agent-都失败在哪" aria-hidden="true">#</a> 第 14 章：失败的 Agent 都失败在哪？</h2><ul><li>无限循环</li><li>工具滥用</li><li>目标漂移</li></ul><p>🧪 示例：Agent 失败案例拆解</p><hr><h1 id="第六部分-实战-从-demo-到-可上线系统" tabindex="-1"><a class="header-anchor" href="#第六部分-实战-从-demo-到-可上线系统" aria-hidden="true">#</a> 第六部分｜实战：从 Demo 到“可上线系统”</h1><blockquote><p><strong>目标：真正跑起来，而不是只在 Notebook 里成功</strong></p></blockquote><hr><h2 id="第-15-章-实战一-可控的多轮对话助手" tabindex="-1"><a class="header-anchor" href="#第-15-章-实战一-可控的多轮对话助手" aria-hidden="true">#</a> 第 15 章：实战一：可控的多轮对话助手</h2><ul><li>Prompt + 记忆 + 参数策略</li></ul><h2 id="第-16-章-实战二-企业知识库问答系统-rag" tabindex="-1"><a class="header-anchor" href="#第-16-章-实战二-企业知识库问答系统-rag" aria-hidden="true">#</a> 第 16 章：实战二：企业知识库问答系统（RAG）</h2><ul><li>文档接入</li><li>检索优化</li><li>引用溯源</li></ul><h2 id="第-17-章-实战三-工具驱动型-agent" tabindex="-1"><a class="header-anchor" href="#第-17-章-实战三-工具驱动型-agent" aria-hidden="true">#</a> 第 17 章：实战三：工具驱动型 Agent</h2><ul><li>Function Calling</li><li>状态管理</li><li>错误恢复</li></ul><hr><h1 id="终章-下一步你该学什么" tabindex="-1"><a class="header-anchor" href="#终章-下一步你该学什么" aria-hidden="true">#</a> 终章｜下一步你该学什么？</h1><ul><li>什么时候该微调？</li><li>什么时候该换模型？</li><li>LLM 应用的长期演进方向</li></ul><hr><h2 id="📌-附录" tabindex="-1"><a class="header-anchor" href="#📌-附录" aria-hidden="true">#</a> 📌 附录</h2><ul><li>Prompt 模板速查表</li><li>RAG 参数调优清单</li><li>Agent 架构设计 Checklist</li><li>常见坑位与反模式总结</li></ul>',138),l=[d];function n(t,o){return e(),r("div",null,l)}const c=a(i,[["render",n],["__file","02.LLM应用开发进阶大纲.html.vue"]]);export{c as default};
