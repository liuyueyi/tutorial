import{_ as t,V as _,W as e,Y as o}from"./framework-b1bd8911.js";const n={},l=o("<blockquote><p>本部分目标：</p><ul><li>解释一个几乎所有真实 LLM 系统都会遇到的问题：<strong>为什么对话一变长，系统就开始失控？</strong></li><li>引入并系统化「Context Engineering（上下文工程）」这一核心思想</li><li>让企业知识库助手从“单轮可用”，升级为“多轮可信”</li></ul></blockquote><p>在第二部分中，我们通过 Prompt 工程为模型建立了单次生成层面的约束—— 比如明确系统角色、限定回答范围、规范输出格式等。这些方法在单轮对话中往往能取得不错的效果：用户问一个问题，系统基于设定的规则和知识库给出答案，<em>看起来</em>既准确又可靠。</p><p>但如果你真正将企业知识库助手投入实际使用，很快就会收到用户这样的反馈：“一开始回答得挺准的，多聊几句就越来越离谱了。”</p><p>这并非 Prompt 突然失效，也不是模型能力下降，而是当对话从 “单轮” 进入 “多轮”，系统面临了一个全新的<strong>挑战维度 —— 时间</strong>。</p><p>在持续交互中，历史信息的累积会逐渐改变模型的输入环境，进而打破最初设定的约束边界。</p><p>接下来，我们将从上下文窗口的本质出发，逐步拆解多轮对话失控的根源，最终落地一套可工程化的上下文管理方案。</p>",6),r=[l];function c(p,s){return _(),e("div",null,r)}const a=t(n,[["render",c],["__file","10.第三部分 上下文与记忆.html.vue"]]);export{a as default};
