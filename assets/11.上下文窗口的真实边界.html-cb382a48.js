const t=JSON.parse('{"key":"v-1813fd7d","path":"/column/ai/llmcoding/11.%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3%E7%9A%84%E7%9C%9F%E5%AE%9E%E8%BE%B9%E7%95%8C.html","title":"第 6 章：上下文窗口的真实边界","lang":"zh-CN","frontmatter":{"order":11,"title":"第 6 章：上下文窗口的真实边界","tag":["LLM"],"category":["LLM"],"date":"2025-12-30T14:05:07.000Z","keywords":"LLM应用开发","description":"在讨论“记忆”之前，我们必须先回答一个技术决策层面的问题： 当用户开始连续提问时，我们是否应该“尽量多地保留历史对话”？ 很多团队在这个问题上的直觉答案是： 当然要保留，历史越完整，模型越能理解上下文，回答自然更准确 但这一章要做的事情，正是推翻这个直觉 —— 因为 “全量保留历史” 不仅无法解决问题，反而会埋下系统失控的隐患。","head":[["meta",{"property":"og:url","content":"https://liuyueyi.github.io/tutorial/column/ai/llmcoding/11.%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3%E7%9A%84%E7%9C%9F%E5%AE%9E%E8%BE%B9%E7%95%8C.html"}],["meta",{"property":"og:site_name","content":"一灰灰的站点"}],["meta",{"property":"og:title","content":"第 6 章：上下文窗口的真实边界"}],["meta",{"property":"og:description","content":"在讨论“记忆”之前，我们必须先回答一个技术决策层面的问题： 当用户开始连续提问时，我们是否应该“尽量多地保留历史对话”？ 很多团队在这个问题上的直觉答案是： 当然要保留，历史越完整，模型越能理解上下文，回答自然更准确 但这一章要做的事情，正是推翻这个直觉 —— 因为 “全量保留历史” 不仅无法解决问题，反而会埋下系统失控的隐患。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-31T02:21:16.000Z"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:published_time","content":"2025-12-30T14:05:07.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-31T02:21:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第 6 章：上下文窗口的真实边界\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-12-30T14:05:07.000Z\\",\\"dateModified\\":\\"2025-12-31T02:21:16.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":3,"title":"6.1 一个常被忽略的事实：上下文不是记忆","slug":"_6-1-一个常被忽略的事实-上下文不是记忆","link":"#_6-1-一个常被忽略的事实-上下文不是记忆","children":[]},{"level":3,"title":"6.2 上下文窗口的三个硬限制（为什么“全塞进去”一定会失败）","slug":"_6-2-上下文窗口的三个硬限制-为什么-全塞进去-一定会失败","link":"#_6-2-上下文窗口的三个硬限制-为什么-全塞进去-一定会失败","children":[]},{"level":3,"title":"6.3 技术决策的失败路径：对话为什么会“慢慢跑偏”？","slug":"_6-3-技术决策的失败路径-对话为什么会-慢慢跑偏","link":"#_6-3-技术决策的失败路径-对话为什么会-慢慢跑偏","children":[]},{"level":3,"title":"6.4 本章小结：一个必须接受的结论","slug":"_6-4-本章小结-一个必须接受的结论","link":"#_6-4-本章小结-一个必须接受的结论","children":[]}],"git":{"createdTime":1767147676000,"updatedTime":1767147676000,"contributors":[{"name":"yihui","email":"bangzewu@126.com","commits":1}]},"readingTime":{"minutes":5.15,"words":1544},"filePathRelative":"column/ai/llmcoding/11.上下文窗口的真实边界.md","localizedDate":"2025年12月30日","excerpt":"<p>在讨论“记忆”之前，我们必须先回答一个<strong>技术决策层面的问题</strong>：</p>\\n<blockquote>\\n<p><strong>当用户开始连续提问时，我们是否应该“尽量多地保留历史对话”？</strong></p>\\n</blockquote>\\n<p>很多团队在这个问题上的直觉答案是：</p>\\n<blockquote>\\n<p><em>当然要保留，历史越完整，模型越能理解上下文，回答自然更准确</em></p>\\n</blockquote>\\n<p>但这一章要做的事情，正是<strong>推翻这个直觉</strong> —— 因为 “全量保留历史” 不仅无法解决问题，反而会埋下系统失控的隐患。</p>","copyright":{},"autoDesc":true}');export{t as data};
